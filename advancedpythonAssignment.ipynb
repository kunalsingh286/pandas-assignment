{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kunalsingh286/pandas-assignment/blob/main/advancedpythonAssignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TCJTl3XGLTJ"
      },
      "source": [
        "Part I: Process Automation\n",
        "\n",
        "Q1. Create a file that contains 1000 lines of random strings.*italicised text*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFRpMWqqGQbm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "\n",
        "# Function to generate a random string of given length\n",
        "def generate_random_string(length=10):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "# Number of lines to generate\n",
        "num_lines = 1000\n",
        "\n",
        "# Generate a list of random strings\n",
        "random_strings = [generate_random_string() for _ in range(num_lines)]\n",
        "\n",
        "# Create a DataFrame from the list of random strings\n",
        "df = pd.DataFrame(random_strings, columns=['RandomString'])\n",
        "\n",
        "# File name to write the random strings\n",
        "file_name = 'random_strings.txt'\n",
        "\n",
        "# Write the DataFrame to a text file, each string on a new line\n",
        "df.to_csv(file_name, header=False, index=False)\n",
        "\n",
        "file_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdJfWytCHEMc"
      },
      "source": [
        "Q2. Create a file that contains multiple lines of random strings and file size must be 5 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmaHLmSNHFgl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "# Function to generate a random string of given length\n",
        "def generate_random_string(length=10):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "# Desired file size in bytes (5 MB)\n",
        "desired_file_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "\n",
        "# Initialize variables\n",
        "file_name = 'random_strings_5MB.txt'\n",
        "total_size = 0\n",
        "strings = []\n",
        "\n",
        "# Generate random strings and keep track of the total size\n",
        "while total_size < desired_file_size:\n",
        "    random_string = generate_random_string()\n",
        "    strings.append(random_string)\n",
        "    total_size += len(random_string) + 1  # +1 for the newline character\n",
        "\n",
        "# Write the strings to the file\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write('\\n'.join(strings) + '\\n')\n",
        "\n",
        "# Verify the file size\n",
        "actual_file_size = os.path.getsize(file_name)\n",
        "print(f\"File created: {file_name}, Size: {actual_file_size} bytes\")\n",
        "\n",
        "file_name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PitehlKlHib8"
      },
      "source": [
        "Q3. Create 10 files that contains multiple lines of random strings and file size of each file must be 5 MB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxqAJKCxII7a"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "# Function to generate a random string of given length\n",
        "def generate_random_string(length=10):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "# Desired file size in bytes (5 MB)\n",
        "desired_file_size = 5 * 1024 * 1024  # 5 MB in bytes\n",
        "\n",
        "# Number of files to create\n",
        "num_files = 10\n",
        "\n",
        "# Create the files\n",
        "file_paths = []  # To store file paths for verification\n",
        "for i in range(1, num_files + 1):\n",
        "    total_size = 0\n",
        "    strings = []\n",
        "    file_name = f'random_strings_{i}.txt'\n",
        "\n",
        "    # Generate random strings and keep track of the total size\n",
        "    while total_size < desired_file_size:\n",
        "        random_string = generate_random_string()\n",
        "        strings.append(random_string)\n",
        "        total_size += len(random_string) + 1  # +1 for the newline character\n",
        "\n",
        "    # Write the strings to the file\n",
        "    with open(file_name, 'w') as file:\n",
        "        file.write('\\n'.join(strings) + '\\n')\n",
        "\n",
        "    # Verify the file size\n",
        "    actual_file_size = os.path.getsize(file_name)\n",
        "    file_paths.append((file_name, actual_file_size))\n",
        "\n",
        "print(\"All files have been created.\")\n",
        "file_paths\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sHMhT_mIpaF"
      },
      "source": [
        "Q4. Create 5 files of size 1GB, 2GB, 3GB, 4GB and 5GB; file contains multiple lines of random strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5kycdZW9K9MV"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import string\n",
        "import os\n",
        "\n",
        "# Function to generate a random string of given length\n",
        "def generate_random_string(length=10):\n",
        "    characters = string.ascii_letters + string.digits\n",
        "    return ''.join(random.choice(characters) for _ in range(length))\n",
        "\n",
        "# Function to create a file with a specified size\n",
        "def create_large_file(file_name, desired_file_size):\n",
        "    total_size = 0\n",
        "    with open(file_name, 'w') as file:\n",
        "        while total_size < desired_file_size:\n",
        "            random_string = generate_random_string()\n",
        "            file.write(random_string + '\\n')\n",
        "            total_size += len(random_string) + 1  # +1 for the newline character\n",
        "    actual_file_size = os.path.getsize(file_name)\n",
        "    print(f\"File created: {file_name}, Size: {actual_file_size} bytes\")\n",
        "\n",
        "# Sizes in bytes\n",
        "sizes = [1 * 1024 * 1024 * 1024,  # 1 GB\n",
        "         2 * 1024 * 1024 * 1024,  # 2 GB\n",
        "         3 * 1024 * 1024 * 1024,  # 3 GB\n",
        "         4 * 1024 * 1024 * 1024,  # 4 GB\n",
        "         5 * 1024 * 1024 * 1024]  # 5 GB\n",
        "\n",
        "# Create the files\n",
        "for i, size in enumerate(sizes, start=1):\n",
        "    file_name = f'large_file_{i}GB.txt'\n",
        "    create_large_file(file_name, size)\n",
        "\n",
        "print(\"All files have been created.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Convert all the files of Q4 into upper case one by one.\n",
        "\n"
      ],
      "metadata": {
        "id": "s18M6Vy_iosV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Function to convert the contents of a file to uppercase\n",
        "def convert_file_to_uppercase(file_name):\n",
        "    temp_file_name = file_name + '.tmp'\n",
        "    with open(file_name, 'r') as infile, open(temp_file_name, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    os.replace(temp_file_name, file_name)\n",
        "    print(f\"File converted to uppercase: {file_name}\")\n",
        "\n",
        "# File names corresponding to the sizes created in Q4\n",
        "file_names = [\n",
        "    'large_file_1GB.txt',\n",
        "    'large_file_2GB.txt',\n",
        "    'large_file_3GB.txt',\n",
        "    'large_file_4GB.txt',\n",
        "    'large_file_5GB.txt'\n",
        "]\n",
        "\n",
        "# Convert each file to uppercase\n",
        "for file_name in file_names:\n",
        "    convert_file_to_uppercase(file_name)\n",
        "\n",
        "print(\"All files have been converted to uppercase.\")\n"
      ],
      "metadata": {
        "id": "ooZ6_ugLiuN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Convert all the files of Q4 into upper case parallel using multi-threading\n",
        "\n"
      ],
      "metadata": {
        "id": "Ysjsl3ofi5KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "# Function to convert the contents of a file to uppercase\n",
        "def convert_file_to_uppercase(file_name):\n",
        "    temp_file_name = file_name + '.tmp'\n",
        "    with open(file_name, 'r') as infile, open(temp_file_name, 'w') as outfile:\n",
        "        for line in infile:\n",
        "            outfile.write(line.upper())\n",
        "    os.replace(temp_file_name, file_name)\n",
        "    print(f\"File converted to uppercase: {file_name}\")\n",
        "\n",
        "# File names corresponding to the sizes created in Q4\n",
        "file_names = [\n",
        "    'large_file_1GB.txt',\n",
        "    'large_file_2GB.txt',\n",
        "    'large_file_3GB.txt',\n",
        "    'large_file_4GB.txt',\n",
        "    'large_file_5GB.txt'\n",
        "]\n",
        "\n",
        "# Convert files to uppercase in parallel using ThreadPoolExecutor\n",
        "with ThreadPoolExecutor(max_workers=len(file_names)) as executor:\n",
        "    executor.map(convert_file_to_uppercase, file_names)\n",
        "\n",
        "print(\"All files have been converted to uppercase.\")\n"
      ],
      "metadata": {
        "id": "BNiyU1C1i_Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. WAP to automatically download 10 images of cat from “Google Images”. [Hint: Find the package from\n",
        "pypi.org and use it]\n",
        "\n"
      ],
      "metadata": {
        "id": "8HmOYaanjEwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google_images_download\n"
      ],
      "metadata": {
        "id": "2oEPmX8MjKoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google_images_download import google_images_download\n",
        "\n",
        "def download_images(query, limit):\n",
        "    response = google_images_download.googleimagesdownload()\n",
        "\n",
        "    arguments = {\n",
        "        \"keywords\": query,\n",
        "        \"limit\": limit,\n",
        "        \"print_urls\": True\n",
        "    }\n",
        "\n",
        "    paths = response.download(arguments)\n",
        "\n",
        "    # Print paths to the downloaded images\n",
        "    print(paths)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set query and limit\n",
        "    query = \"cat\"  # Query for cat images\n",
        "    limit = 10  # Number of images to download\n",
        "\n",
        "    # Call download function\n",
        "    download_images(query, limit)\n"
      ],
      "metadata": {
        "id": "QeBECGJFjTo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. WAP to automatically download 10 videos of “Machine Learning” from “Youtube.com”. [Hint: Find the\n",
        "package from pypi.org and use it\n",
        "\n"
      ],
      "metadata": {
        "id": "mVKwgSFxjUj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube\n"
      ],
      "metadata": {
        "id": "Khpjr6YfjbTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "\n",
        "def download_videos(query, limit):\n",
        "    query_string = query.replace(' ', '+')\n",
        "    youtube_url = f\"https://www.youtube.com/results?search_query={query_string}\"\n",
        "\n",
        "    # Fetching the search result page\n",
        "    yt = YouTube(youtube_url)\n",
        "    search_results = yt.search(query, limit=limit)\n",
        "\n",
        "    for i, video in enumerate(search_results):\n",
        "        try:\n",
        "            yt = YouTube(video['url'])\n",
        "            video_stream = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "\n",
        "            print(f\"Downloading video {i+1}: {video['title']}...\")\n",
        "            video_stream.download(filename=f\"video_{i+1}\")\n",
        "            print(f\"Downloaded video {i+1}: {video['title']} successfully!\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading video {i+1}: {video['title']}\")\n",
        "            print(str(e))\n",
        "            continue\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set query and limit\n",
        "    query = \"Machine Learning\"  # Query for Machine Learning videos\n",
        "    limit = 10  # Number of videos to download\n",
        "\n",
        "    # Call download function\n",
        "    download_videos(query, limit)\n"
      ],
      "metadata": {
        "id": "EwpoIsr3jelg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Convert all the videos of Q8 and convert it to audio. [Hint: Find the package from pypi.org and use it]\n",
        "\n"
      ],
      "metadata": {
        "id": "cigfGzcxjkUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube moviepy\n"
      ],
      "metadata": {
        "id": "N46bSTtIjoR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "def download_videos_and_convert_to_audio(query, limit):\n",
        "    query_string = query.replace(' ', '+')\n",
        "    youtube_url = f\"https://www.youtube.com/results?search_query={query_string}\"\n",
        "\n",
        "    # Fetching the search result page\n",
        "    yt = YouTube(youtube_url)\n",
        "    search_results = yt.search(query, limit=limit)\n",
        "\n",
        "    for i, video in enumerate(search_results):\n",
        "        try:\n",
        "            yt = YouTube(video['url'])\n",
        "\n",
        "            # Download video\n",
        "            print(f\"Downloading video {i+1}: {video['title']}...\")\n",
        "            video_stream = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "            video_stream.download(filename=f\"video_{i+1}.mp4\")\n",
        "            print(f\"Downloaded video {i+1}: {video['title']} successfully!\")\n",
        "\n",
        "            # Convert video to audio\n",
        "            video_path = f\"video_{i+1}.mp4\"\n",
        "            audio_path = f\"audio_{i+1}.mp3\"\n",
        "\n",
        "            print(f\"Converting video {i+1} to audio...\")\n",
        "            clip = VideoFileClip(video_path)\n",
        "            clip.audio.write_audiofile(audio_path)\n",
        "            print(f\"Converted video {i+1} to audio successfully!\\n\")\n",
        "\n",
        "            # Clean up - delete the original video file\n",
        "            clip.close()\n",
        "            os.remove(video_path)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {i+1}: {video['title']}\")\n",
        "            print(str(e))\n",
        "            continue\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import os\n",
        "\n",
        "    # Set query and limit\n",
        "    query = \"Machine Learning\"  # Query for Machine Learning videos\n",
        "    limit = 10  # Number of videos to download and convert\n",
        "\n",
        "    # Call download and convert function\n",
        "    download_videos_and_convert_to_audio(query, limit)\n"
      ],
      "metadata": {
        "id": "eWZvfvIojrga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Create an automated pipeline using multi-threading for:\n",
        "“Automatic Download of 100 Videos from YouTube” → “Convert it to Audio\""
      ],
      "metadata": {
        "id": "_g8g2-yijyyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube moviepy\n"
      ],
      "metadata": {
        "id": "fA6lzI80j1Vf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import os\n",
        "from queue import Queue\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import VideoFileClip\n",
        "\n",
        "class VideoDownloader(threading.Thread):\n",
        "    def __init__(self, queue):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.queue = queue\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            # Get a video URL from the queue\n",
        "            video_url = self.queue.get()\n",
        "\n",
        "            try:\n",
        "                # Download video\n",
        "                print(f\"Downloading video from {video_url}...\")\n",
        "                yt = YouTube(video_url)\n",
        "                video_stream = yt.streams.filter(progressive=True, file_extension='mp4').first()\n",
        "                video_path = video_stream.download()\n",
        "                print(f\"Downloaded video: {video_path}\")\n",
        "\n",
        "                # Put video path into conversion queue\n",
        "                conversion_queue.put(video_path)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading {video_url}: {str(e)}\")\n",
        "\n",
        "            finally:\n",
        "                self.queue.task_done()\n",
        "\n",
        "class VideoConverter(threading.Thread):\n",
        "    def __init__(self, queue):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.queue = queue\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            # Get a video path from the queue\n",
        "            video_path = self.queue.get()\n",
        "\n",
        "            try:\n",
        "                # Convert video to audio\n",
        "                print(f\"Converting {video_path} to audio...\")\n",
        "                clip = VideoFileClip(video_path)\n",
        "                audio_path = f\"{os.path.splitext(video_path)[0]}.mp3\"\n",
        "                clip.audio.write_audiofile(audio_path)\n",
        "                print(f\"Converted {video_path} to {audio_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error converting {video_path} to audio: {str(e)}\")\n",
        "\n",
        "            finally:\n",
        "                # Clean up - delete the original video file\n",
        "                clip.close()\n",
        "                os.remove(video_path)\n",
        "                self.queue.task_done()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set query and limit\n",
        "    query = \"Machine Learning\"  # Query for Machine Learning videos\n",
        "    limit = 100  # Number of videos to download and convert\n",
        "\n",
        "    # Create a queue for video URLs\n",
        "    video_queue = Queue()\n",
        "    conversion_queue = Queue()\n",
        "\n",
        "    # Create threads for downloading videos\n",
        "    for i in range(5):  # You can adjust the number of threads as needed\n",
        "        downloader = VideoDownloader(video_queue)\n",
        "        downloader.daemon = True\n",
        "        downloader.start()\n",
        "\n",
        "    # Create threads for converting videos to audio\n",
        "    for i in range(5):  # You can adjust the number of threads as needed\n",
        "        converter = VideoConverter(conversion_queue)\n",
        "        converter.daemon = True\n",
        "        converter.start()\n",
        "\n",
        "    # Fetch video URLs from YouTube search results\n",
        "    query_string = query.replace(' ', '+')\n",
        "    youtube_url = f\"https://www.youtube.com/results?search_query={query_string}\"\n",
        "    yt = YouTube(youtube_url)\n",
        "    search_results = yt.search(query, limit=limit)\n",
        "\n",
        "    # Add video URLs to video queue\n",
        "    for video in search_results:\n",
        "        video_queue.put(video['url'])\n",
        "\n",
        "    # Wait for all videos to be downloaded and converted\n",
        "    video_queue.join()\n",
        "    conversion_queue.join()\n"
      ],
      "metadata": {
        "id": "lOzpKqw6j4TO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. Create an automated pipeline using multi-threading for: “Automatic Download of 500 images of Dog from\n",
        "GoogleImages” → “Rescale it to 50%”.\n",
        "\n"
      ],
      "metadata": {
        "id": "S30YEctbkDjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google_images_download Pillow\n"
      ],
      "metadata": {
        "id": "pxGZm6BqkEPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import threading\n",
        "import requests\n",
        "import shutil\n",
        "from queue import Queue\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from google_images_download import google_images_download\n",
        "\n",
        "class ImageDownloader(threading.Thread):\n",
        "    def __init__(self, query, limit, queue):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.query = query\n",
        "        self.limit = limit\n",
        "        self.queue = queue\n",
        "\n",
        "    def run(self):\n",
        "        response = google_images_download.googleimagesdownload()\n",
        "\n",
        "        arguments = {\n",
        "            \"keywords\": self.query,\n",
        "            \"limit\": self.limit,\n",
        "            \"print_urls\": False,\n",
        "            \"no_download\": True\n",
        "        }\n",
        "\n",
        "        paths = response.download(arguments)\n",
        "        urls = paths[0][self.query]\n",
        "\n",
        "        for i, url in enumerate(urls):\n",
        "            try:\n",
        "                # Download image from URL\n",
        "                print(f\"Downloading image {i+1}/{self.limit} from {url}...\")\n",
        "                response = requests.get(url, stream=True)\n",
        "                image = Image.open(BytesIO(response.content))\n",
        "\n",
        "                # Put image into resizing queue\n",
        "                self.queue.put(image)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error downloading image {i+1}/{self.limit} from {url}: {str(e)}\")\n",
        "\n",
        "            finally:\n",
        "                self.queue.task_done()\n",
        "\n",
        "class ImageResizer(threading.Thread):\n",
        "    def __init__(self, queue):\n",
        "        threading.Thread.__init__(self)\n",
        "        self.queue = queue\n",
        "\n",
        "    def run(self):\n",
        "        while True:\n",
        "            # Get an image from the queue\n",
        "            image = self.queue.get()\n",
        "\n",
        "            try:\n",
        "                # Resize the image to 50%\n",
        "                width, height = image.size\n",
        "                new_width = int(width * 0.5)\n",
        "                new_height = int(height * 0.5)\n",
        "                resized_image = image.resize((new_width, new_height))\n",
        "\n",
        "                # Save the resized image\n",
        "                output_path = f\"resized_image_{os.getpid()}.jpg\"  # Change the filename as needed\n",
        "                resized_image.save(output_path)\n",
        "                print(f\"Resized image saved: {output_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error resizing image: {str(e)}\")\n",
        "\n",
        "            finally:\n",
        "                # Clean up - close the image\n",
        "                self.queue.task_done()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set query and limit\n",
        "    query = \"Dog\"  # Query for Dog images\n",
        "    limit = 500  # Number of images to download and resize\n",
        "\n",
        "    # Create a queue for images\n",
        "    image_queue = Queue()\n",
        "\n",
        "    # Create threads for downloading images\n",
        "    downloader = ImageDownloader(query, limit, image_queue)\n",
        "    downloader.start()\n",
        "\n",
        "    # Create threads for resizing images\n",
        "    resizer_threads = []\n",
        "    for i in range(5):  # You can adjust the number of resizing threads as needed\n",
        "        resizer = ImageResizer(image_queue)\n",
        "        resizer_threads.append(resizer)\n",
        "        resizer.start()\n",
        "\n",
        "    # Wait for all images to be resized\n",
        "    downloader.join()\n",
        "    image_queue.join()\n",
        "\n",
        "    # Clean up - join all resizing threads\n",
        "    for resizer in resizer_threads:\n",
        "        resizer.join()\n",
        "\n"
      ],
      "metadata": {
        "id": "F1vGa8fjkJF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "4-Re1n17igfu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5HuENGGDsgyoX02d5q3U6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}